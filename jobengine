#!/usr/bin/perl
#
# Simple job scheduler.
# Monitor $JOBQUEUE for new job files. Each jobfile spawns a process that runs
# Job->process(). The scheduler defaults to 4 concurrent processes.
#
# Soren Juul Moller, Nov 2019

use strict;
use warnings;
use Getopt::Std;
use Carp qw(longmess);
use Parallel::Fork::BossWorkerAsync ();
use Linux::Inotify2;
use BaseConfig;
use Utils;
use Logger;
use RinexSet;
use Job;

my %Running;
my $Debug = 1;  	# set with -d option


#####################################
# Submit a dayjob on an incomplete day
#
sub force_completion($$$) {
  my ($site, $year, $doy) = @_;

  loginfo("Force completion of $site-$year-$doy");
  my $dayjob = new Job(site => $site, year => $year, doy => $doy);
  my $workdir = $dayjob->getWorkdir;

  # Find interval
  my $interval;
  foreach my $hour ('a'..'x') {
    next unless -f "$workdir/rs.$hour.json";
    my $rs = new RinexSet(rsfile => "$workdir/rs.$hour.json");
    $interval = $rs->{'interval'};
    last if defined $interval;
  }

  # Submit dayjob
  if (defined $interval) {
    ($dayjob->{'hour'}, $dayjob->{'interval'}, $dayjob->{'incomplete'}) = ('0', $interval, 1);
    $dayjob->submitjob('hour2daily');
    writefile("$workdir/status.0", 'queued');
  } else {
    logerror("6:Cannot force completion of $site-$year-$doy. No proccessed hours.");
  }
}


#####################################
# Look for forced incomplete days and submit them
#
sub scan_for_forced_incompletes() {
  sub dirscan($) {
    my $dir = shift;
    opendir(my $dh, $dir);
    my @dirs = grep { index($_,'.') != 0 && -d "$dir/$_" } readdir($dh);
    closedir($dh);
    return @dirs;
  }
  foreach my $site (dirscan($WORKDIR)) {
    foreach my $year (dirscan("$WORKDIR/$site")) {
      foreach my $doy (dirscan("$WORKDIR/$site/$year")) {
        my $w = "$WORKDIR/$site/$year/$doy";
        next unless -f "$w/force-complete";
        unlink("$w/force-complete");
        force_completion($site, $year, $doy);
      }
    }
  }
}


#####################################
# Run command issued by someone like admin.cgi
#
sub runcommand($) {
  my $cmd = shift;

  if ($cmd =~ /^reload ftpuploader/) {
    sysrun("systemctl reload ftpuploader");
  }
  elsif ($cmd =~ /^force complete (\w+) (\d+) (\d+)/) {
    force_completion($1, $2, $3);
  }
}


#####################################
# This sub is runned by the fork manager,
# It calls Job->process and returns the result.
#
sub runjob($) {
  my $jobfileref = shift;
  my ($jobfile, $content) = ($jobfileref->{'jobfile'}, $jobfileref->{'content'});

  # If filename ends with 'command', then assume it is a command file
  if ($jobfile =~ /command$/) {
    # message from admin.cgi
    runcommand($content);
    return { ident => 'command', result => 'ok' };
  }

  # otherwise assume it's a JSON file
  my $job = new Job(json => $content);
  my $ident = $job->getIdent();
  my $res = { ident => $ident, result => 'error' };

  unless (defined $job && $job->verifyobj()) {
    logerror("invalid jobfile $jobfile");
    return $res;
  }

  # Duplicate event check
  if (exists $Running{$ident}) {
    logerror("Duplicate job $ident");
    return $res;
  }

  my $workdir = $job->getWorkdir;
  chdir($workdir);

  my $statusfile = "status.".$job->{'hour'};
  if (-f $statusfile && readfile($statusfile) eq 'running') {
    logerror("Duplicate job");
    return $res;
  }
  writefile($statusfile, 'running');

  loginfo("Run $ident");
  eval {
    $job->process();
    1;
  } || do {
    logerror("FATAL ERROR: ".longmess($ident));	# Serious program error occurred.
    $res->{'result'} = 'fatal';
    return $res;
  };

  $res->{'result'} = 'ok';
  return $res;
}

#
# Executed when the worker is forked
#
sub init_worker() {
  setprogram("job");
}

# Initialize BossWorkerAsync
sub start_bw($) {
  my $instances = shift;
  return Parallel::Fork::BossWorkerAsync->new(
	work_handler => \&runjob,
	init_handler => \&init_worker,
	global_timeout => 0,		# Disable timeouts
	worker_count => $instances,
  );
}

########################################################################################################
# Main program
#
my %opts = ();
getopts('c:di:l:', \%opts);

BaseConfig::init($opts{'c'}) if defined $opts{'c'};

my $log = (defined $opts{'l'} ? $opts{'l'} : "/dev/null");
$Debug = 1 if defined $opts{'d'};

my $Ninstances = (defined $opts{'i'} ? $opts{'i'} : $JOBINSTANCES);

setprogram($0);
$0 = basename($0)." ".join(' ',@ARGV);

#select(STDERR); $| = 1;         # Unbuffered output
#select(STDOUT); $| = 1;         # Unbuffered output

my $BW = start_bw($Ninstances);
loginfo("jobengine started with $Ninstances instances");

# Setup queue event handler
my $inotify = new Linux::Inotify2;
$inotify->blocking(0);
my $watcher = $inotify->watch($JOBQUEUE, IN_MOVED_TO | IN_CLOSE_WRITE);

# main loop
my $signal_received = '';
$SIG{INT} = sub { $signal_received = 'interrupt' };
$SIG{TERM} = sub { $signal_received = 'terminated' };
$SIG{HUP} = 'IGNORE';

my @RunQueue = ();

# Enqueue jobs already in jobspool
foreach (dirlist($JOBQUEUE)) {
  my $fn = "$JOBQUEUE/$_";
  push(@RunQueue, { jobfile => $fn, content => readfile($fn) });
  unlink($fn);
}

my $ntimeouts = 0;
my $need_restart = 0;
while (!$signal_received) {
  my $v = '';
  vec($v, $inotify->fileno, 1) = 1;
  select($v, undef, undef, 1);			# wait 1s for inotify has something
  if (vec($v, $inotify->fileno, 1)) {
    $ntimeouts = 0;
    my @events = $inotify->read;		# Read all events available
    foreach my $e (@events) {
      push(@RunQueue, { jobfile => $e->fullname, content => readfile($e->fullname) });
      unlink($e->fullname);
    }
  } else {
    $ntimeouts++;
    while (my $q = shift(@RunQueue)) {		# enqueue all jobs read by inotify
      $BW->add_work($q);
    }
    if ($BW->pending()) {			# Do we have outstanding results?
      my $res = $BW->get_result_nb();		# Try get a result
      next unless defined $res;			# Wait for next file if nothing yet...
      logerror($res->{'ERROR'}) if $res->{'ERROR'};
      delete $Running{$res->{'ident'}};
      if ($res->{'result'} eq 'fatal') {
        $need_restart = 1;
      }
    }
    if ($ntimeouts % 600 == 0) {		# For every 10min idle time, check for leftovers
      foreach (dirlist($JOBQUEUE)) {
        my $fn = "$JOBQUEUE/$_";
        next unless fileage($fn) < 900;
        push(@RunQueue, { jobfile => $fn, content => readfile($fn) });
        unlink($fn);
      }
      scan_for_forced_incompletes();
    }
    if ($need_restart) {
      loginfo("Restarting fork manager due to fatal error");
      $watcher->cancel;
      $BW->shut_down;
      $BW = start_nw($Ninstances);
      $watcher = $inotify->watch($JOBQUEUE, IN_MOVED_TO | IN_CLOSE_WRITE);
      $need_restart = 0;
      loginfo("Fork manager restarted.");
    }
  }
}
loginfo($signal_received) if $signal_received;

$watcher->cancel;
$BW->shut_down();

# Restore unfinished jobs into jobspool
while (my $q = shift(@RunQueue)) {
  writefile($q->{'jobfile'}, $q->{'content'});
}

loginfo("$0 stopped");
logclose();
exit(0);
