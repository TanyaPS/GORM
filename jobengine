#!/usr/bin/perl
#
# Simple job scheduler.
# Monitor $JOBQUEUE for new job files. Each jobfile spawns a process that do the
# conversion and distribution. The scheduler defaults to 4 concurrent processes.
#
# Soren Juul Moller, Nov 2019

use strict;
use warnings;
use Getopt::Std;
use Fcntl qw(:DEFAULT :flock);
use Parallel::ForkManager;
use Linux::Inotify2;
use BaseConfig;
use Utils;
use Logger;
use Job;

my %Jobs;	# Queued jobs
my %Running;	# Running jobs
my $Debug = 0;  # set with -d option

sub lock($) {
  my $fn = shift;
  my $fd;
  return 0 unless sysopen($fd, $fn, O_CREAT|O_RDWR);
  flock($fd, LOCK_EX);
  return $fd;
}

sub unlock($) {
  my $fd = shift;
  return if $fd == 0; # if lock failed
  flock($fd, LOCK_UN);
  close($fd);
}

########################################
# Manipulate $workdir/status.json.
# Requires exclusive access
#
sub statusdb($;$$) {
  my ($jsonfile, $hour, $status) = @_;
  my $json = loadJSON($jsonfile);
  $json = {} unless defined $json;
  if (!defined $status && !defined $hour) {
    $status = $json;
  } elsif (!defined $status) {
    $status = defined $json->{$hour} ? $json->{$hour} : "";
  } else {
    $json->{$hour} = $status;
    storeJSON($jsonfile, $json);
  }
  return $status;
}

##########################################
# Callback called when a child starts
#
sub onstart() {
  my ($pid, $ident) = @_;
  loginfo("$ident starting") if $Debug;
}

##########################################
# Callback called when a child finishes
#
sub onfinish() {
  my ($pid, $exitcode, $ident) = @_;
  return unless defined $ident && defined $Running{$ident};
  my ($site, $year, $doy, $hour) = split(/-/, $ident);
  my $job = $Running{$ident};
  my $workdir = $job->getWorkdir;
  my $statusfile = "$workdir/status.json";

  loginfo("$ident finished") if $Debug;
  delete $Running{$ident};

  return unless -d $workdir;  # may have been removed
  my $lockfd = lock($statusfile);
  statusdb($statusfile, $hour, "processed");

  # check if day is complete (status.json still locked)
  if ($hour ne '0') {
    my $status = statusdb($statusfile);
    if (!exists $status->{'0'}) {
      my $complete = 1;
      foreach my $h ('a'..'x') {
        $complete = 0 unless exists $status->{$h} && $status->{$h} eq "processed";
      }
      if ($complete) {
        my $dayjob = new Job(site => $site, year => $year, doy => $doy, hour => '0', interval => $job->{'interval'});
        $dayjob->submitjob('hour2daily');
        statusdb($statusfile, '0', "queued");  # make sure nobody else do the same
      }
    }
  }
  unlock($lockfd);
}

#####################################
# Spawn a job using ForkManager
#
sub runjob($$) {
  my ($FM, $job) = @_;
  loginfo("Run ".$job->getIdent) if $Debug;
  $FM->start($job->getIdent()) && return;  # start instance
  setprogram("job");
  chdir($job->getWorkdir());
  $job->process();
  $FM->finish(0);		# exit this instance
}

########################################################################################################
# Main program
#
my %opts = ();
getopts('di:l:', \%opts);
my $log = (defined $opts{'l'} ? $opts{'l'} : "/dev/null");
$Debug = 1 if defined $opts{'d'};
my $Ninstances = (defined $opts{'i'} ? $opts{'i'} : 4);

setprogram($0);
$0 = basename($0)." ".join(' ',@ARGV);

# Handle HUP, INT and TERM signal niecly
my $sig_received = "";
sub signal_handler {
  $sig_received = shift;
  loginfo("$sig_received signal received. Exiting...");
}
local $SIG{HUP} = 'IGNORE';
local $SIG{INT} = \&signal_handler;
local $SIG{TERM} = \&signal_handler;
local $SIG{ALRM} = sub { };

select(STDERR); $| = 1;         # Unbuffered output
select(STDOUT); $| = 1;         # Unbuffered output

# Initialize ForkManager
my $FM = new Parallel::ForkManager($Ninstances);
$FM->run_on_start(\&onstart);
$FM->run_on_finish(\&onfinish);

# Setup queue event handler
my $inotify = new Linux::Inotify2;
my $watcher = $inotify->watch($JOBQUEUE, IN_MOVED_TO | IN_CLOSE_WRITE);

# main loop
while ($sig_received eq "") {
  # ForkManager needs reaping of finished childs to force callback
  $FM->reap_finished_children;

  # Read job directory
  my @joblist = dirlist($JOBQUEUE);

  # Enqueue all jobs in job directory
  foreach my $jobfile (@joblist) {
    my $job = new Job(jobfile => "$JOBQUEUE/$jobfile");
    unlink("$JOBQUEUE/$jobfile");
    next unless defined $job && defined $job->{'site'};
    my $ident = $job->getIdent;
    next if exists $Running{$ident} || exists $Jobs{$ident};
    $Jobs{$job->getIdent} = $job;
  }

  # If no files in job directory, enter wait for new files
  if (scalar(keys %Jobs) == 0) {
    # queue empty, wait for a new job
    alarm 11;
    my @e = $inotify->read;
    alarm 0;
    foreach my $jobfile (@e) {
      next unless -f $jobfile->fullname;
      my $job = new Job(jobfile => $jobfile->fullname);
      unlink($jobfile->fullname);
      $Jobs{$job->getIdent} = $job;
    }
  }

  # Process all jobs in job queue
  # Lock status.json file, as many processes access it.
  foreach my $ident (keys %Jobs) {
    last if $sig_received;
    my $job = $Jobs{$ident};
    my $workdir = $job->getWorkdir;
    my $statusfile = "$workdir/status.json";
    my $lockfd = lock($statusfile);
    my $status = statusdb($statusfile, $job->{'hour'});
    if ($status eq "running" || $status eq "processed") {
      unlock($lockfd);
      loginfo("Duplicate job $ident");
    } else {
      statusdb($statusfile, $job->{'hour'}, "running");
      unlock($lockfd);
      runjob($FM, $job);
      $Running{$ident} = $job;
    }
    delete $Jobs{$ident};
  }
}

$watcher->cancel;
$FM->wait_all_children;

# Write unfinished jobs back into queue
foreach my $job (keys %Jobs) {
  $job->submitjob($job->{'source'});
  loginfo("Unfinished job ".$job->getIdent()." resubmitted");
}

