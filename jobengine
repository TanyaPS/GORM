#!/usr/bin/perl
#
# Simple job scheduler.
# Monitor $JOBQUEUE for new job files. Each jobfile spawns a process that do the
# conversion and distribution. The scheduler defaults to 4 concurrent processes.
#
# Soren Juul Moller, Nov 2019

use strict;
use warnings;
use Getopt::Std;
use Fcntl qw(:DEFAULT :flock);
use Parallel::ForkManager;
use Linux::Inotify2;
use BaseConfig;
use Utils;
use Logger;
use RinexSet;
use Job;

my $PollInterval = 11;	# Poll timeout seconds
my %Running;
my $Debug = 1;  	# set with -d option
my $FM;			# FormManager

# Lock a named file
sub lock($) {
  my $fn = shift;
  my $fd;
  return 0 unless sysopen($fd, $fn, O_CREAT|O_RDWR);
  flock($fd, LOCK_EX);
  return $fd;
}

# Unlcok file descriptor
sub unlock($) {
  my $fd = shift;
  return if $fd == 0; # if lock failed
  flock($fd, LOCK_UN);
  close($fd);
}

########################################
# Manipulate $workdir/status.json.
# Requires exclusive access
#
sub statusdb($;$$) {
  my ($jsonfile, $hour, $status) = @_;
  my $json = loadJSON($jsonfile);
  $json = {} unless defined $json;
  if (!defined $status && !defined $hour) {
    $status = $json;
  } elsif (!defined $status) {
    $status = defined $json->{$hour} ? $json->{$hour} : "";
  } else {
    $json->{$hour} = $status;
    storeJSON($jsonfile, $json);
  }
  return $status;
}

##########################################
# Callback called when a child starts
#
sub onstart() {
  my ($pid, $ident) = @_;
  loginfo("$ident starting");
}

##########################################
# Callback called when a child finishes
#
sub onfinish() {
  my ($pid, $exitcode, $ident) = @_;
  my ($site, $year, $doy, $hour) = split(/-/, $ident);
  my $job = $Running{$ident};
  my $workdir = $job->getWorkdir;
  my $statusfile = "$workdir/status.json";

  loginfo("$ident finished");
  delete $Running{$ident};

  return unless -d $workdir;  # may have been removed
  my $lockfd = lock($statusfile);
  statusdb($statusfile, $hour, "processed");

  # check if day is complete (status.json still locked)
  if ($hour ne '0') {
    my $status = statusdb($statusfile);
    if (!exists $status->{'0'}) {
      my $complete = 1;
      foreach my $h ('a'..'x') {
        $complete = 0 unless exists $status->{$h} && $status->{$h} eq "processed";
      }
      if ($complete) {
        my $dayjob = new Job(site => $site, year => $year, doy => $doy, hour => '0', interval => $job->{'interval'});
        $dayjob->submitjob('hour2daily');
        statusdb($statusfile, '0', "queued");  # make sure nobody else do the same
      }
    }
  }
  unlock($lockfd);
}

#####################################
# Submit a dayjob on an incomplete day
#
sub force_completion($$$) {
  my ($site, $year, $doy) = @_;

  loginfo("Force completion of $site-$year-$doy");
  my $dayjob = new Job(site => $site, year => $year, doy => $doy);
  my $workdir = $dayjob->getWorkdir;
  my $statusfile = "$workdir/status.json";
  my $lock = lock($statusfile);
  my $sta = statusdb($statusfile);

  # Find interval
  my $interval;
  foreach my $hour (keys %$sta) {
    next unless $sta->{$hour} eq 'processed';
    my $rs = new RinexSet(rsfile => "$workdir/rs.$hour.json");
    $interval = $rs->{'interval'};
    last if defined $interval;
  }

  # Submit dayjob
  if (defined $interval) {
    ($dayjob->{'hour'}, $dayjob->{'interval'}, $dayjob->{'incomplete'}) = ('0', $interval, 1);
    $dayjob->submitjob('hour2daily');
    statusdb($statusfile, '0', "queued");
  } else {
    logerror("Cannot force completion of $site-$year-$doy. No proccessed hours.");
  }
  unlock($lock);
}


#####################################
# Look for forced incomplete days and submit them
#
sub scan_for_forced_incompletes() {
  sub dirscan($) {
    my $dir = shift;
    opendir(my $dh, $dir);
    my @dirs = grep { index($_,'.') != 0 && -d "$dir/$_" } readdir($dh);
    closedir($dh);
    return @dirs;
  }
  foreach my $site (dirscan($WORKDIR)) {
    foreach my $year (dirscan("$WORKDIR/$site")) {
      foreach my $doy (dirscan("$WORKDIR/$site/$year")) {
        my $w = "$WORKDIR/$site/$year/$doy";
        next unless -f "$w/force-complete" && -f "$w/status.json";
        unlink("$w/force-complete");
        force_completion($site, $year, $doy);
      }
    }
  }
}

#####################################
# Run command issued by someone like admin.cgi
#
sub runcommand($) {
  my $file = shift;
  open(my $fd, '<', $file);
  my $cmd = <$fd>; chomp;
  close($fd);

  if ($cmd =~ /^reload ftpuploader/) {
    sysrun("systemctl reload ftpuploader");
  }
  elsif ($cmd =~ /^force complete (\w+) (\d+) (\d+)/) {
    force_completion($1, $2, $3);
  }
}

#####################################
# Spawn a job using ForkManager
#
sub runjob($) {
  my $jobfile = shift;

  # If filename ends with 'command', then assume it is a command file
  if ($jobfile =~ /command$/) {
    # message from admin.cgi
    runcommand($jobfile);
    unlink($jobfile);
    return;
  }

  # otherwise assume it's a JSON file
  my $job = new Job(jobfile => $jobfile);
  unlink($jobfile);

  my $ident = $job->getIdent;
  my $workdir = $job->getWorkdir;
  my $statusfile = "$workdir/status.json";
  my $lockfd = lock($statusfile);
  my $status = statusdb($statusfile, $job->{'hour'});
  if ($status eq "running" || $status eq "processed") {
    unlock($lockfd);
    loginfo("Duplicate job $ident");
    return;
  } else {
    statusdb($statusfile, $job->{'hour'}, "running");
    unlock($lockfd);
  }
  loginfo("Run $ident");

  $Running{$ident} = $job;		# need this in onfinish()
  $FM->start($ident) && return;  	# start instance
  setprogram("job");
  chdir($workdir);
  eval {
    $job->process();
    return 1;
  } || do {
    logerror("FATAL ERROR: $@");	# Serious program error occurred.
  };
  $FM->finish(0);			# exit this instance
}

#####################################
# Inotify2 callback
# Called for each new file arrived in queue
#
sub inotify_callback() {
  my $event = shift;
  alarm 0;
  runjob($event->fullname);
  alarm $PollInterval;
}

########################################################################################################
# Main program
#
my %opts = ();
getopts('di:l:', \%opts);
my $log = (defined $opts{'l'} ? $opts{'l'} : "/dev/null");
$Debug = 1 if defined $opts{'d'};
my $Ninstances = (defined $opts{'i'} ? $opts{'i'} : $JOBINSTANCES);

setprogram($0);
$0 = basename($0)." ".join(' ',@ARGV);

local $SIG{HUP} = 'IGNORE';

select(STDERR); $| = 1;         # Unbuffered output
select(STDOUT); $| = 1;         # Unbuffered output

# Initialize ForkManager
$FM = new Parallel::ForkManager($Ninstances);
$FM->run_on_start(\&onstart);
$FM->run_on_finish(\&onfinish);

# Run jobs in queue already
runjob("$JOBQUEUE/$_") foreach dirlist($JOBQUEUE);

# Setup queue event handler
my $inotify = new Linux::Inotify2;
my $watcher = $inotify->watch($JOBQUEUE, IN_MOVED_TO | IN_CLOSE_WRITE, \&inotify_callback);

# Need a fast poll interval to reap finished childs quickly
# But we do not need to scan files that frequently
my $lastscan = time();
my $scaninterval = 300;		# Scan for force-complete every 5 min

# main loop
while (1) {
  # ForkManager needs reaping of finished childs to force callback
  $FM->reap_finished_children;

  eval {
    local $SIG{ALRM} = sub { die("jobenginealarm"); };
    local $SIG{INT} = sub { die("interrupted"); };
    local $SIG{TERM} = sub { die("terminated"); };
    alarm $PollInterval;
    $inotify->poll;	# wait for new file in $INCOMING
    alarm 0;
  };
  if ($@) {
    my $msg = $@;
    if ($msg =~ /^jobenginealarm/) {
      runjob("$JOBQUEUE/$_") foreach dirlist($JOBQUEUE);
      if (time() > $lastscan + $scaninterval) {
        scan_for_forced_incompletes();
        $lastscan = time();
      }
    } elsif ($msg =~ /^(\w+)/) {
      loginfo($1);
      last;
    }
  }
}

$watcher->cancel;
$FM->wait_all_children;
